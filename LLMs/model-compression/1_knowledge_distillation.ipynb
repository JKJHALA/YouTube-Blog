{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLeHWEijGmrT"
   },
   "source": [
    "# Knowledge Distillation Example\n",
    "\n",
    "Code authored by: Shaw Talebi\n",
    "\n",
    "[Video](https://youtu.be/FLkUOkeMd5M) <br>\n",
    "[Blog](https://towardsdatascience.com/compressing-large-language-models-llms-9f406eea5b5e) <br>\n",
    "[Colab](https://colab.research.google.com/drive/1B6kHngy3cC2i1VFa4saG9tliCvPPoFw0?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_hN9U0-GseU"
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertConfig\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDVEk7pSGuy1"
   },
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"shawhin/phishing-site-classification\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYkSD6IuGyAg"
   },
   "source": [
    "### load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher model and tokenizer\n",
    "model_path = \"shawhin/bert-phishing-classifier_teacher\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "teacher_model = AutoModelForSequenceClassification.from_pretrained(model_path).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load student model\n",
    "my_config = DistilBertConfig(n_heads=8, n_layers=4) # drop 4 heads per layer and 2 layers\n",
    "\n",
    "student_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",\n",
    "                                                                    config=my_config,).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWQwVekG7Mr"
   },
   "source": [
    "### tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define text preprocessing\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding='max_length', truncation=True)\n",
    "\n",
    "# tokenize all datasetse\n",
    "tokenized_data = data.map(preprocess_function, batched=True)\n",
    "tokenized_data.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf4XJX-1H8fz"
   },
   "source": [
    "### evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model performance\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disable gradient calculations\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            # Forward pass to get logits\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            # Get predictions\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sk_MXDgG-C9"
   },
   "source": [
    "### train student model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute distillation and hard-label loss\n",
    "def distillation_loss(student_logits, teacher_logits, true_labels, temperature, alpha):\n",
    "    # Compute soft targets from teacher logits\n",
    "    soft_targets = nn.functional.softmax(teacher_logits / temperature, dim=1)\n",
    "    student_soft = nn.functional.log_softmax(student_logits / temperature, dim=1)\n",
    "\n",
    "    # KL Divergence loss for distillation\n",
    "    distill_loss = nn.functional.kl_div(student_soft, soft_targets, reduction='batchmean') * (temperature ** 2)\n",
    "\n",
    "    # Cross-entropy loss for hard labels\n",
    "    hard_loss = nn.CrossEntropyLoss()(student_logits, true_labels)\n",
    "\n",
    "    # Combine losses\n",
    "    loss = alpha * distill_loss + (1.0 - alpha) * hard_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "num_epochs = 5\n",
    "temperature = 2.0\n",
    "alpha = 0.5\n",
    "\n",
    "# define optimizer\n",
    "optimizer = optim.Adam(student_model.parameters(), lr=lr)\n",
    "\n",
    "# create training data loader\n",
    "dataloader = DataLoader(tokenized_data['train'], batch_size=batch_size)\n",
    "# create testing data loader\n",
    "test_dataloader = DataLoader(tokenized_data['test'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put student model in train mode\n",
    "student_model.train()\n",
    "\n",
    "# train model\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # Prepare inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        # Disable gradient calculation for teacher model\n",
    "        with torch.no_grad():\n",
    "            teacher_outputs = teacher_model(input_ids, attention_mask=attention_mask)\n",
    "            teacher_logits = teacher_outputs.logits\n",
    "\n",
    "        # Forward pass through the student model\n",
    "        student_outputs = student_model(input_ids, attention_mask=attention_mask)\n",
    "        student_logits = student_outputs.logits\n",
    "\n",
    "        # Compute the distillation loss\n",
    "        loss = distillation_loss(student_logits, teacher_logits, labels, temperature, alpha)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1} completed with loss: {loss.item()}\")\n",
    "\n",
    "    # Evaluate the teacher model\n",
    "    teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, test_dataloader, device)\n",
    "    print(f\"Teacher (test) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
    "\n",
    "    # Evaluate the student model\n",
    "    student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, test_dataloader, device)\n",
    "    print(f\"Student (test) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # put student model back into train mode\n",
    "    student_model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6XDcYkZHPIL"
   },
   "source": [
    "### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create testing data loader\n",
    "validation_dataloader = DataLoader(tokenized_data['validation'], batch_size=8)\n",
    "\n",
    "# Evaluate the teacher model\n",
    "teacher_accuracy, teacher_precision, teacher_recall, teacher_f1 = evaluate_model(teacher_model, validation_dataloader, device)\n",
    "print(f\"Teacher (validation) - Accuracy: {teacher_accuracy:.4f}, Precision: {teacher_precision:.4f}, Recall: {teacher_recall:.4f}, F1 Score: {teacher_f1:.4f}\")\n",
    "\n",
    "# Evaluate the student model\n",
    "student_accuracy, student_precision, student_recall, student_f1 = evaluate_model(student_model, validation_dataloader, device)\n",
    "print(f\"Student (validation) - Accuracy: {student_accuracy:.4f}, Precision: {student_precision:.4f}, Recall: {student_recall:.4f}, F1 Score: {student_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gqWrm20LAFl"
   },
   "source": [
    "### Push to Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.push_to_hub(\"shawhin/bert-phishing-classifier_student\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
